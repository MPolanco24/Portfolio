# -*- coding: utf-8 -*-
"""VAE_Model_Miguel_Polanco.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1861omXGjNy0FH94S8QSdvyFLTC46q6XF
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
import tensorflow.keras as kr
from keras import metrics, optimizers, regularizers
from scipy.stats import norm
from numpy.random import seed
seed(1)
# %matplotlib inline
import warnings
warnings.filterwarnings('ignore')
from google.colab import files
from sklearn.model_selection import train_test_split
import joblib
from sklearn.preprocessing import MinMaxScaler,StandardScaler
import matplotlib as mpl
from sklearn import metrics
import seaborn as sns
from sklearn.metrics import (confusion_matrix, precision_recall_curve, auc,roc_curve, recall_score, classification_report, f1_score,precision_recall_fscore_support)
import keras

#Data Upload
uploaded = files.upload()

#Data Reading
data = pd.read_csv('network_attack_data.csv')
data.head()

data['Label'].value_counts()

#DataFrame creation for Benign and Attack
benign = data['Label']== 0
attack = data['Label']!= 0

data_benign = data[benign]
data_attack = data[attack]

print(f"Benign count: {len(data_benign)}")
print(f"Attack count: {len(data_attack)}")

#Converting the dataframes into numpy arrays and dropping the Label column
x_benign = data_benign.drop('Label',axis=1).values
y_benign = data_benign['Label'].values

x_attack = data_attack.drop('Label',axis=1).values
y_attack = data_attack['Label'].values

print(x_benign.shape, x_attack.shape)
print(y_benign.shape, y_attack.shape)

#Splitting the data into Test and Train
x_benign_train, x_benign_test = train_test_split(x_benign, test_size=0.25, random_state=301299027)
print(x_benign_train.shape, x_benign_test.shape)

#Scaling the data using MinMaxScaler
scaler=MinMaxScaler()
x_benign_tr_scaled= scaler.fit_transform(x_benign_train)
x_benign_tst_scaled= scaler.transform(x_benign_test)
x_attack_scaled= scaler.transform(x_attack)

#Set Hyperparameters
batch_size = 64
num_features = 76
latent_dim = 5
hidden_layer_1 = 100
hidden_layer_2 = 100
epochs = 50

#Defining the Encoder
inputs = kr.layers.Input(shape=(num_features, ), name='input')
x1 = kr.layers.Dense(hidden_layer_1, activation='relu')(inputs)
x2 = kr.layers.Dense(hidden_layer_2, activation='relu')(x1)
z_mean = kr.layers.Dense(latent_dim, name='z_mean')(x2)
z_log_var = kr.layers.Dense(latent_dim, name='z_log_var')(x2)

#Defining Sampling Layer
def sampling(args):
    z_mean, z_log_var = args
    eps = tf.random.normal(tf.shape(z_log_var), dtype=tf.float32, mean=0., stddev=1.0, name='epsilon')
    z = z_mean + tf.exp(z_log_var / 2) * eps
    return z

z = kr.layers.Lambda(sampling, name='z')([z_mean, z_log_var])

encoder = kr.Model(inputs, [z_mean, z_log_var, z], name='encoder')
encoder.summary()

#Defining the Decoder
latent_inputs = kr.layers.Input(shape=(latent_dim,), name='z_sampling')
x1 = kr.layers.Dense(hidden_layer_2, activation='relu')(latent_inputs)
x2 = kr.layers.Dense(hidden_layer_1, activation='relu')(x1)
outputs = kr.layers.Dense(num_features, activation='sigmoid')(x2)

decoder = kr.Model(latent_inputs, outputs, name='decoder')
decoder.summary()

#Instantiate of the VAE Model
outputs = decoder(encoder(inputs)[2])
vae = kr.Model(inputs, outputs, name='vae')

#Defining VAE loss and Optimizer

# Reconstruction loss
reconstruction_loss = tf.losses.mean_squared_error(inputs, outputs)
reconstruction_loss = reconstruction_loss * num_features

# KL Divergence loss
kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)
kl_loss = -0.5 * tf.reduce_sum(kl_loss, axis=-1)
vae_loss = tf.reduce_mean(reconstruction_loss + kl_loss)

vae.add_loss(vae_loss)
adam = optimizers.Adam(learning_rate=0.001)
vae.compile(optimizer=adam)
vae.summary()

#Training Model
model= vae.fit(x_benign_tr_scaled ,x_benign_tr_scaled, verbose = 1, batch_size=batch_size, epochs=epochs,shuffle=True,validation_split=0.2)

#Displaying the Loss Curve during training
mpl.rcParams['font.size'] = 24
plt.rcParams["figure.figsize"] = (15,12)
plt.plot(model.history['loss'],linewidth = 8)
plt.plot(model.history['val_loss'],linewidth = 8)

plt.ylabel('Reconstruction Error/loss',fontsize = 24)
plt.xlabel('epoch',fontsize = 24)
plt.legend(['train_data', 'val_data'], loc='best',fontsize = 20)
plt.show()

#Saving Encoder, Decoder and VAE Models
save_model = keras.callbacks.ModelCheckpoint("VAE_model.h5", save_best_only=True)

#Making predictions on Test Data
pred1 = vae.predict(x_benign_tr_scaled)
score1 = np.sqrt(metrics.mean_squared_error(pred1,x_benign_tr_scaled))

pred2 = vae.predict(x_benign_tst_scaled)
score2 = np.sqrt(metrics.mean_squared_error(pred2,x_benign_tst_scaled))

pred3 = vae.predict(x_attack_scaled)
score3 = np.sqrt(metrics.mean_squared_error(pred3,x_attack_scaled))

print(f"Benign_training_data Score (RMSE): {score1}")
print(f"Benign_test_data_score Score (RMSE): {score2}")
print(f"Attack_test_data_score (RMSE): {score3}")

tst_obs = x_benign_tst_scaled.copy()
print(tst_obs.shape)
tst_obs = np.append(tst_obs, x_attack_scaled, axis=0)
print(tst_obs.shape)
print(y_benign[0:5747].shape)

Y_obs = y_benign[0:5747].copy()
Y_obs = np.append(Y_obs, y_attack, axis=0)
print(Y_obs.shape)

#Making predictions using the VAE model
test_preds = vae.predict(tst_obs)
mse_test = np.mean(np.power(tst_obs- test_preds, 2), axis=1)
mse_test.shape

tst_error_data = pd.DataFrame({'recon_error': mse_test,'Label': Y_obs})

group1 = tst_error_data.groupby('Label')
fig, ax = plt.subplots()
for name, group in group1:
    ax.plot(group.index, group.recon_error, marker='o', ms=3.5, linestyle='',label= "Attack" if name == 1 else "Benign")
ax.legend()
plt.ylabel("Reconstruction error")
plt.xlabel("Data point index")
plt.show()

# Metric Analysis with Threshold

threshold=0.0115 ##selected using trial and error based on improving the TPR and TNR values

y_pred = [1 if e > threshold else 0 for e in tst_error_data.recon_error.values]

cm= confusion_matrix(tst_error_data.Label, y_pred)
print("Confusion matrix:")
print(cm)

tn = cm[0][0]
fp = cm[0][1]
fn = cm[1][0]
tp = cm[1][1]

print("\nTotal number of true positives", tp)
print("Total number of false negatives",fn)
print("Total number of false positives",fp)
print("Total number of true negatives",tn)

acc=float(tp+tn)/(tp+tn+fp+fn)

print('\nClassifier Accuracy: %.2f%%' % (acc * 100))

tpr = float(tp)/(tp+fn)

print('True Positive Rate (TPR/Recall/Sensitivity): %.2f%%' % (tpr * 100))

specificity = float (tn)/(tn+fp)

print ("True Negative Rate (TNR/Specificity/selectivity):%.2f%%" % (specificity*100))

fpr = float(fp)/(fp+tn)
print("False Positive Rate (FPR): %.2f%%" % (fpr * 100))

fnr = fn/ (fn+ tp)
print("False Negative Rate (FNR): %.2f%%" % (fnr*100))

precision=float(tp)/(tp+fp)
print("Precision/Positive Predictive value:%.2f%%" %(precision*100))

fscore = 2*((precision*tpr)/(precision+tpr))
print("F1-Score: %.2f%%" %(fscore*100))

#ROC Graph
fpr, tpr, thresholds = roc_curve(tst_error_data.Label,tst_error_data.recon_error)
roc_auc = auc(fpr, tpr)
plt.title('Receiver Operating Characteristic')
plt.plot(fpr, tpr, label='AUC = %0.2f'% roc_auc,linewidth = 8, color='b')
plt.legend(loc='lower right')
plt.plot([0,1],[0,1],'r--',linewidth = 4)
plt.xlim([-0.001, 1])
plt.ylim([0, 1.001])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()